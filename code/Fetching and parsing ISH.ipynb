{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting hourly temperature data from NOAA ISD (integrated surface database) weather data\n",
    "\n",
    "ish_parser python module is from:\n",
    "https://github.com/haydenth/ish_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# boilerplate includes\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "#mpl.use('nbagg')\n",
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#import mpld3 # for outputting interactive html figures\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import ish_parser\n",
    "import gzip\n",
    "import ftplib\n",
    "import io\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "%matplotlib notebook\n",
    "plt.style.use('seaborn-notebook')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching and parsing  KLAX\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS (might be overridden by a calling script)\n",
    "\n",
    "# if not calling from another script (batch), SUBNOTEBOOK_FLAG might not be defined\n",
    "try:\n",
    "    SUBNOTEBOOK_FLAG\n",
    "except NameError:\n",
    "    SUBNOTEBOOK_FLAG = False\n",
    "    \n",
    "# Not calling as a sub-script? define params here\n",
    "if not SUBNOTEBOOK_FLAG:\n",
    "    \n",
    "    # SET PARAMETER VARIABLES HERE UNLESS CALLING USING %run FROM ANOTHER NOTEBOOK\n",
    "    \n",
    "    STATION_CALLSIGN = 'KLAX'\n",
    "\n",
    "    USE_CACHED_STATION_H5_FILES = True\n",
    "    SUPPRESS_FIGURE_DISPLAY = False\n",
    "\n",
    "    DATADIR = '../data/temperatures/ISD'\n",
    "    OUTDIR = '../data/temperatures'\n",
    "\n",
    "    FTPHOST = 'ftp.ncdc.noaa.gov'\n",
    "    FETCH_STATIONS_LIST_FILE = True\n",
    "    \n",
    "print(\"Fetching and parsing \",STATION_CALLSIGN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Locate the station info...\n",
    "\n",
    "Could either do it by hand, or else try to get all the data associated with a single station callsign. The latter seems like a cooler way to go... but have to be careful that the stations really are the same and the data is comparable for our purposes.\n",
    "\n",
    "stations list: ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if FETCH_STATIONS_LIST_FILE:\n",
    "    # fetch a fresh copy of the stations list\n",
    "    with open(os.path.join(DATADIR,'isd-history.txt'),'wb') as fh:\n",
    "        with ftplib.FTP(host=FTPHOST) as ftpconn:\n",
    "            ftpconn.login()\n",
    "            ftpconn.retrbinary('RETR '+'/pub/data/noaa/isd-history.txt', fh.write)\n",
    "            ftpconn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to parse stations list file\n",
    "def read_isd_history_stations_list(filename, skiprows=22):\n",
    "    \"\"\"Read and parse stations information from isd_history.txt file\"\"\"\n",
    "    fwfdef = (( ('USAF', (6, str)),\n",
    "                ('WBAN', (5, str)),\n",
    "                ('STATION NAME', (28, str)),\n",
    "                ('CTRY', (4, str)),\n",
    "                ('ST', (2, str)),\n",
    "                ('CALL', (5, str)),\n",
    "                ('LAT', (7, str)),\n",
    "                ('LON', (8, str)),\n",
    "                ('EVEV', (7, str)),\n",
    "                ('BEGIN', (8, str)),\n",
    "                ('END', (8, str)),\n",
    "                ))\n",
    "    names = []\n",
    "    colspecs = []\n",
    "    converters = {}\n",
    "    i = 0\n",
    "    for k,v in fwfdef:\n",
    "        names.append(k)\n",
    "        colspecs.append((i, i+v[0]+1))\n",
    "        i += v[0]+1\n",
    "        converters[k] = v[1]\n",
    "    stdf = pd.read_fwf(filename, skiprows=skiprows,\n",
    "                       names=names,\n",
    "                       colspecs=colspecs,\n",
    "                       converters=converters)\n",
    "    return stdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# actually parse the file\n",
    "stationsdf = read_isd_history_stations_list(\n",
    "    os.path.join(DATADIR,'isd-history.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USAF</th>\n",
       "      <th>WBAN</th>\n",
       "      <th>STATION NAME</th>\n",
       "      <th>CTRY</th>\n",
       "      <th>ST</th>\n",
       "      <th>CALL</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>EVEV</th>\n",
       "      <th>BEGIN</th>\n",
       "      <th>END</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18862</th>\n",
       "      <td>722950</td>\n",
       "      <td>23174</td>\n",
       "      <td>LOS ANGELES INTERNATIONAL AIR</td>\n",
       "      <td>US</td>\n",
       "      <td>CA</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>+33.938</td>\n",
       "      <td>-118.389</td>\n",
       "      <td>+0029.6</td>\n",
       "      <td>19440101</td>\n",
       "      <td>20170819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29330</th>\n",
       "      <td>999999</td>\n",
       "      <td>23174</td>\n",
       "      <td>LOS ANGELES MUNICIPAL ARPT</td>\n",
       "      <td>US</td>\n",
       "      <td>CA</td>\n",
       "      <td>KLAX</td>\n",
       "      <td>+33.938</td>\n",
       "      <td>-118.389</td>\n",
       "      <td>+0099.4</td>\n",
       "      <td>19470101</td>\n",
       "      <td>19721231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         USAF   WBAN                   STATION NAME CTRY  ST  CALL      LAT  \\\n",
       "18862  722950  23174  LOS ANGELES INTERNATIONAL AIR   US  CA  KLAX  +33.938   \n",
       "29330  999999  23174     LOS ANGELES MUNICIPAL ARPT   US  CA  KLAX  +33.938   \n",
       "\n",
       "            LON     EVEV     BEGIN       END  \n",
       "18862  -118.389  +0029.6  19440101  20170819  \n",
       "29330  -118.389  +0099.4  19470101  19721231  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick just the info associated with the station we want\n",
    "station_info = stationsdf[stationsdf['CALL'] == STATION_CALLSIGN]\n",
    "station_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # maybe only use a subset of these entires\n",
    "# station_info = station_info.iloc[2:3]\n",
    "# station_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the actual data\n",
    "data files are at:ftp://ftp.ncdc.noaa.gov/pub/data/noaa/{YEAR}/{USAF}-{WBAN}-{YEAR}.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_ish_data(usaf_id, wban_id, years_to_get, \n",
    "                      ftp_host=FTPHOST,\n",
    "                      verbose=True):\n",
    "    parser = ish_parser.ish_parser()\n",
    "    with ftplib.FTP(host=ftp_host) as ftpconn:\n",
    "        ftpconn.login()\n",
    "        for year in years_to_get:\n",
    "            ftp_file = \"/pub/data/noaa/{YEAR}/{USAF}-{WBAN}-{YEAR}.gz\".format(\n",
    "                USAF=usaf_id, WBAN=wban_id, YEAR=year)\n",
    "            if verbose:\n",
    "                print(ftp_file)\n",
    "            # read the whole file and save it to a BytesIO (stream)\n",
    "            response = io.BytesIO()\n",
    "            try:\n",
    "                ftpconn.retrbinary('RETR '+ftp_file, response.write)\n",
    "            except ftplib.error_perm as err:\n",
    "                if str(err).startswith('550 '):\n",
    "                    print('ERROR:', err)\n",
    "                else:\n",
    "                    raise\n",
    "            # decompress and parse each line \n",
    "            response.seek(0) # jump back to the beginning of the stream\n",
    "            with gzip.open(response, mode='rb') as gzstream:\n",
    "                for line in gzstream:\n",
    "                    parser.loads(line.decode('latin-1'))\n",
    "    # get the list of all reports\n",
    "    reports = parser.get_reports()\n",
    "    if verbose:\n",
    "        print(len(reports), \"records\")\n",
    "    # just return None if no records were found\n",
    "    if len(reports) <= 0:\n",
    "        return None\n",
    "    # convert to a pandas dataframe\n",
    "    foo = pd.DataFrame.from_records(\n",
    "                ((r.datetime, r.air_temperature.get_numeric()) for r in reports),\n",
    "                columns=['datetime','AT'],\n",
    "                index='datetime')\n",
    "    foo.index = pd.to_datetime(foo.index) # convert the index to pandas datetime objects\n",
    "    foo.dropna(inplace=True) # drop entires which don't have an AT value\n",
    "    foo.sort_index(inplace=True) # go ahead and ensure it is sorted\n",
    "    return foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### 722950 23174 range(1944, 2018)\n",
      "/pub/data/noaa/1944/722950-23174-1944.gz\n",
      "/pub/data/noaa/1945/722950-23174-1945.gz\n",
      "ERROR: 550 /pub/data/noaa/1945/722950-23174-1945.gz: No such file or directory\n",
      "/pub/data/noaa/1946/722950-23174-1946.gz\n",
      "ERROR: 550 /pub/data/noaa/1946/722950-23174-1946.gz: No such file or directory\n",
      "/pub/data/noaa/1947/722950-23174-1947.gz\n",
      "ERROR: 550 /pub/data/noaa/1947/722950-23174-1947.gz: No such file or directory\n",
      "/pub/data/noaa/1948/722950-23174-1948.gz\n",
      "ERROR: 550 /pub/data/noaa/1948/722950-23174-1948.gz: No such file or directory\n",
      "/pub/data/noaa/1949/722950-23174-1949.gz\n",
      "ERROR: 550 /pub/data/noaa/1949/722950-23174-1949.gz: No such file or directory\n",
      "/pub/data/noaa/1950/722950-23174-1950.gz\n",
      "ERROR: 550 /pub/data/noaa/1950/722950-23174-1950.gz: No such file or directory\n",
      "/pub/data/noaa/1951/722950-23174-1951.gz\n",
      "ERROR: 550 /pub/data/noaa/1951/722950-23174-1951.gz: No such file or directory\n",
      "/pub/data/noaa/1952/722950-23174-1952.gz\n",
      "ERROR: 550 /pub/data/noaa/1952/722950-23174-1952.gz: No such file or directory\n",
      "/pub/data/noaa/1953/722950-23174-1953.gz\n",
      "ERROR: 550 /pub/data/noaa/1953/722950-23174-1953.gz: No such file or directory\n",
      "/pub/data/noaa/1954/722950-23174-1954.gz\n",
      "ERROR: 550 /pub/data/noaa/1954/722950-23174-1954.gz: No such file or directory\n",
      "/pub/data/noaa/1955/722950-23174-1955.gz\n",
      "ERROR: 550 /pub/data/noaa/1955/722950-23174-1955.gz: No such file or directory\n",
      "/pub/data/noaa/1956/722950-23174-1956.gz\n",
      "ERROR: 550 /pub/data/noaa/1956/722950-23174-1956.gz: No such file or directory\n",
      "/pub/data/noaa/1957/722950-23174-1957.gz\n",
      "ERROR: 550 /pub/data/noaa/1957/722950-23174-1957.gz: No such file or directory\n",
      "/pub/data/noaa/1958/722950-23174-1958.gz\n",
      "ERROR: 550 /pub/data/noaa/1958/722950-23174-1958.gz: No such file or directory\n",
      "/pub/data/noaa/1959/722950-23174-1959.gz\n",
      "ERROR: 550 /pub/data/noaa/1959/722950-23174-1959.gz: No such file or directory\n",
      "/pub/data/noaa/1960/722950-23174-1960.gz\n",
      "ERROR: 550 /pub/data/noaa/1960/722950-23174-1960.gz: No such file or directory\n",
      "/pub/data/noaa/1961/722950-23174-1961.gz\n",
      "ERROR: 550 /pub/data/noaa/1961/722950-23174-1961.gz: No such file or directory\n",
      "/pub/data/noaa/1962/722950-23174-1962.gz\n",
      "ERROR: 550 /pub/data/noaa/1962/722950-23174-1962.gz: No such file or directory\n",
      "/pub/data/noaa/1963/722950-23174-1963.gz\n",
      "ERROR: 550 /pub/data/noaa/1963/722950-23174-1963.gz: No such file or directory\n",
      "/pub/data/noaa/1964/722950-23174-1964.gz\n",
      "ERROR: 550 /pub/data/noaa/1964/722950-23174-1964.gz: No such file or directory\n",
      "/pub/data/noaa/1965/722950-23174-1965.gz\n",
      "ERROR: 550 /pub/data/noaa/1965/722950-23174-1965.gz: No such file or directory\n",
      "/pub/data/noaa/1966/722950-23174-1966.gz\n",
      "ERROR: 550 /pub/data/noaa/1966/722950-23174-1966.gz: No such file or directory\n",
      "/pub/data/noaa/1967/722950-23174-1967.gz\n",
      "ERROR: 550 /pub/data/noaa/1967/722950-23174-1967.gz: No such file or directory\n",
      "/pub/data/noaa/1968/722950-23174-1968.gz\n",
      "ERROR: 550 /pub/data/noaa/1968/722950-23174-1968.gz: No such file or directory\n",
      "/pub/data/noaa/1969/722950-23174-1969.gz\n",
      "ERROR: 550 /pub/data/noaa/1969/722950-23174-1969.gz: No such file or directory\n",
      "/pub/data/noaa/1970/722950-23174-1970.gz\n",
      "ERROR: 550 /pub/data/noaa/1970/722950-23174-1970.gz: No such file or directory\n",
      "/pub/data/noaa/1971/722950-23174-1971.gz\n",
      "ERROR: 550 /pub/data/noaa/1971/722950-23174-1971.gz: No such file or directory\n",
      "/pub/data/noaa/1972/722950-23174-1972.gz\n",
      "ERROR: 550 /pub/data/noaa/1972/722950-23174-1972.gz: No such file or directory\n",
      "/pub/data/noaa/1973/722950-23174-1973.gz\n",
      "/pub/data/noaa/1974/722950-23174-1974.gz\n",
      "/pub/data/noaa/1975/722950-23174-1975.gz\n",
      "/pub/data/noaa/1976/722950-23174-1976.gz\n",
      "/pub/data/noaa/1977/722950-23174-1977.gz\n",
      "/pub/data/noaa/1978/722950-23174-1978.gz\n",
      "/pub/data/noaa/1979/722950-23174-1979.gz\n",
      "/pub/data/noaa/1980/722950-23174-1980.gz\n",
      "/pub/data/noaa/1981/722950-23174-1981.gz\n",
      "/pub/data/noaa/1982/722950-23174-1982.gz\n",
      "/pub/data/noaa/1983/722950-23174-1983.gz\n",
      "/pub/data/noaa/1984/722950-23174-1984.gz\n",
      "/pub/data/noaa/1985/722950-23174-1985.gz\n",
      "/pub/data/noaa/1986/722950-23174-1986.gz\n",
      "/pub/data/noaa/1987/722950-23174-1987.gz\n",
      "/pub/data/noaa/1988/722950-23174-1988.gz\n",
      "/pub/data/noaa/1989/722950-23174-1989.gz\n",
      "/pub/data/noaa/1990/722950-23174-1990.gz\n",
      "/pub/data/noaa/1991/722950-23174-1991.gz\n",
      "/pub/data/noaa/1992/722950-23174-1992.gz\n",
      "/pub/data/noaa/1993/722950-23174-1993.gz\n",
      "/pub/data/noaa/1994/722950-23174-1994.gz\n",
      "/pub/data/noaa/1995/722950-23174-1995.gz\n",
      "/pub/data/noaa/1996/722950-23174-1996.gz\n",
      "/pub/data/noaa/1997/722950-23174-1997.gz\n",
      "/pub/data/noaa/1998/722950-23174-1998.gz\n",
      "/pub/data/noaa/1999/722950-23174-1999.gz\n",
      "/pub/data/noaa/2000/722950-23174-2000.gz\n",
      "/pub/data/noaa/2001/722950-23174-2001.gz\n",
      "/pub/data/noaa/2002/722950-23174-2002.gz\n",
      "/pub/data/noaa/2003/722950-23174-2003.gz\n",
      "/pub/data/noaa/2004/722950-23174-2004.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:unable to load report, error: Non matching lengths. Expected 1407, got 1346\n",
      "WARNING:root:unable to load report, error: Non matching lengths. Expected 1409, got 1348\n",
      "WARNING:root:unable to load report, error: Non matching lengths. Expected 1425, got 1348\n",
      "WARNING:root:unable to load report, error: Non matching lengths. Expected 1423, got 1346\n",
      "WARNING:root:unable to load report, error: Non matching lengths. Expected 1423, got 1346\n",
      "WARNING:root:unable to load report, error: Non matching lengths. Expected 1351, got 1290\n",
      "WARNING:root:unable to load report, error: Non matching lengths. Expected 1425, got 1348\n",
      "WARNING:root:unable to load report, error: Non matching lengths. Expected 1407, got 1346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pub/data/noaa/2005/722950-23174-2005.gz\n",
      "/pub/data/noaa/2006/722950-23174-2006.gz\n",
      "/pub/data/noaa/2007/722950-23174-2007.gz\n",
      "/pub/data/noaa/2008/722950-23174-2008.gz\n",
      "/pub/data/noaa/2009/722950-23174-2009.gz\n",
      "/pub/data/noaa/2010/722950-23174-2010.gz\n",
      "/pub/data/noaa/2011/722950-23174-2011.gz\n",
      "/pub/data/noaa/2012/722950-23174-2012.gz\n",
      "/pub/data/noaa/2013/722950-23174-2013.gz\n",
      "/pub/data/noaa/2014/722950-23174-2014.gz\n",
      "/pub/data/noaa/2015/722950-23174-2015.gz\n",
      "/pub/data/noaa/2016/722950-23174-2016.gz\n",
      "/pub/data/noaa/2017/722950-23174-2017.gz\n",
      "552567 records\n",
      "Saving station data to: '../data/temperatures/ISD/722950-23174-AT.h5'\n",
      "#### 999999 23174 range(1947, 1973)\n",
      "/pub/data/noaa/1947/999999-23174-1947.gz\n",
      "/pub/data/noaa/1948/999999-23174-1948.gz\n",
      "/pub/data/noaa/1949/999999-23174-1949.gz\n",
      "/pub/data/noaa/1950/999999-23174-1950.gz\n",
      "/pub/data/noaa/1951/999999-23174-1951.gz\n",
      "/pub/data/noaa/1952/999999-23174-1952.gz\n",
      "/pub/data/noaa/1953/999999-23174-1953.gz\n",
      "/pub/data/noaa/1954/999999-23174-1954.gz\n",
      "/pub/data/noaa/1955/999999-23174-1955.gz\n",
      "/pub/data/noaa/1956/999999-23174-1956.gz\n",
      "/pub/data/noaa/1957/999999-23174-1957.gz\n",
      "/pub/data/noaa/1958/999999-23174-1958.gz\n",
      "/pub/data/noaa/1959/999999-23174-1959.gz\n",
      "/pub/data/noaa/1960/999999-23174-1960.gz\n",
      "/pub/data/noaa/1961/999999-23174-1961.gz\n",
      "/pub/data/noaa/1962/999999-23174-1962.gz\n",
      "/pub/data/noaa/1963/999999-23174-1963.gz\n",
      "/pub/data/noaa/1964/999999-23174-1964.gz\n",
      "/pub/data/noaa/1965/999999-23174-1965.gz\n",
      "/pub/data/noaa/1966/999999-23174-1966.gz\n",
      "/pub/data/noaa/1967/999999-23174-1967.gz\n",
      "/pub/data/noaa/1968/999999-23174-1968.gz\n",
      "/pub/data/noaa/1969/999999-23174-1969.gz\n",
      "/pub/data/noaa/1970/999999-23174-1970.gz\n",
      "/pub/data/noaa/1971/999999-23174-1971.gz\n",
      "/pub/data/noaa/1972/999999-23174-1972.gz\n",
      "227900 records\n",
      "Saving station data to: '../data/temperatures/ISD/999999-23174-AT.h5'\n",
      "Saving combined data to: 'KLAX_AT.h5'\n",
      "CPU times: user 1min 40s, sys: 3 s, total: 1min 43s\n",
      "Wall time: 6min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = None\n",
    "for _,row in station_info.iterrows():\n",
    "    usaf_id = row['USAF']\n",
    "    wban_id = row['WBAN']\n",
    "    years_to_get = range(int(row['BEGIN'][0:4]), int(row['END'][0:4])+1)\n",
    "    print('####', usaf_id, wban_id, years_to_get)\n",
    "\n",
    "    station_h5file = os.path.join(DATADIR,\n",
    "                \"{USAF}-{WBAN}-AT.h5\".format(USAF=usaf_id, WBAN=wban_id))\n",
    "\n",
    "    station_df = None\n",
    "    if USE_CACHED_STATION_H5_FILES:\n",
    "        if os.path.isfile(station_h5file):\n",
    "            print(\"Using cached file: '{}'\".format(station_h5file))\n",
    "            station_df = pd.read_hdf(station_h5file, 'table')\n",
    "\n",
    "    if station_df is None:\n",
    "        station_df = download_ish_data(usaf_id, wban_id, years_to_get, ftp_host=FTPHOST)\n",
    "    \n",
    "    if station_df is None:\n",
    "        print(\"WARNING: No data found for {} {} {}\".format(usaf_id, wban_id, years_to_get))\n",
    "    else:\n",
    "    \n",
    "        # Save this station's individual data\n",
    "        print(\"Saving station data to: '{}'\".format(station_h5file))\n",
    "        station_df.to_hdf(station_h5file,'table')\n",
    "\n",
    "        # Combine into single dataset\n",
    "        if df is None:\n",
    "            df = station_df.copy(deep=True)\n",
    "        else:\n",
    "            # @TCC TODO: Maybe use some more clever logic than just \"combine_first\"\n",
    "            df = df.combine_first(station_df)\n",
    "\n",
    "# ensure the final combined dataset is sorted\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# save the combined datafram\n",
    "combined_AT_filename = \"{}_AT.h5\".format(STATION_CALLSIGN)\n",
    "print(\"Saving combined data to: '{}'\".format(combined_AT_filename))\n",
    "df.to_hdf(os.path.join(DATADIR, combined_AT_filename),'table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Plot (decomment to enable)\n",
    "\n",
    "# if SUPPRESS_FIGURE_DISPLAY:\n",
    "#     plt.ioff()\n",
    "# ax = df.plot(title=STATION_CALLSIGN, marker='.')\n",
    "# ax.set_ylabel('air temperature [$\\degree$ C]')\n",
    "# plt.savefig(os.path.join(OUTDIR,'{}_AT_orig.png'.format(STATION_CALLSIGN)))\n",
    "# plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Distribution plot (decomment to enable)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(1,1,1)\n",
    "# sns.kdeplot(df['AT'], bw=.5, ax=ax, legend=False)\n",
    "# ax.set_xlabel('air temperature [$\\degree$C]')\n",
    "# ax.set_ylabel('proportion of readings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
